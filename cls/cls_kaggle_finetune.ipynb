{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9049b1c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T17:33:56.593887Z",
     "iopub.status.busy": "2025-11-24T17:33:56.593507Z",
     "iopub.status.idle": "2025-11-25T01:55:56.030960Z",
     "shell.execute_reply": "2025-11-25T01:55:56.030102Z"
    },
    "papermill": {
     "duration": 30119.44247,
     "end_time": "2025-11-25T01:55:56.032242",
     "exception": false,
     "start_time": "2025-11-24T17:33:56.589772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISIBLE classes: ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
      "PARTIAL raw classes: ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
      "Classes: ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n",
      "Train class counts (vis+partial): {0: 18184, 1: 4497, 2: 3373, 3: 4770, 4: 3892, 5: 7387, 6: 4934, 7: 6917, 8: 7809, 9: 4748, 10: 7112, 11: 16586}\n",
      "Weak classes: (2, 1)\n",
      "Boosting loss weight for class 2 by x3.0\n",
      "Boosting loss weight for class 1 by x3.0\n",
      "=== Start finetune on visible + partial ===\n",
      "[FT] Epoch 1/50  vis_acc=0.4730, par_acc=0.3515\n",
      "    vis per-class: 0:0.13, 1:0.36, 2:0.00, 3:0.82, 4:0.89, 5:0.93, 6:0.98, 7:0.97, 8:1.00, 9:0.80, 10:1.00, 11:0.57\n",
      "    par per-class: 0:0.00, 1:0.07, 2:0.00, 3:0.58, 4:0.73, 5:0.62, 6:0.55, 7:0.71, 8:0.40, 9:0.17, 10:0.67, 11:0.14\n",
      "[FT] Epoch 2/50  vis_acc=0.5092, par_acc=0.3473\n",
      "    vis per-class: 0:0.26, 1:0.29, 2:0.00, 3:0.86, 4:0.90, 5:0.94, 6:0.99, 7:0.95, 8:1.00, 9:0.58, 10:1.00, 11:0.47\n",
      "    par per-class: 0:0.00, 1:0.04, 2:0.00, 3:0.62, 4:0.74, 5:0.64, 6:0.58, 7:0.63, 8:0.39, 9:0.08, 10:0.74, 11:0.12\n",
      "[FT] Epoch 3/50  vis_acc=0.4870, par_acc=0.3288\n",
      "    vis per-class: 0:0.25, 1:0.25, 2:0.00, 3:0.79, 4:0.80, 5:0.97, 6:0.96, 7:0.95, 8:0.99, 9:0.35, 10:1.00, 11:0.51\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.54, 4:0.70, 5:0.68, 6:0.46, 7:0.60, 8:0.35, 9:0.05, 10:0.60, 11:0.18\n",
      "[FT] Epoch 4/50  vis_acc=0.5209, par_acc=0.3832\n",
      "    vis per-class: 0:0.23, 1:0.34, 2:0.00, 3:0.68, 4:0.94, 5:0.98, 6:0.99, 7:0.91, 8:1.00, 9:0.64, 10:0.98, 11:0.73\n",
      "    par per-class: 0:0.00, 1:0.06, 2:0.00, 3:0.41, 4:0.78, 5:0.73, 6:0.63, 7:0.58, 8:0.42, 9:0.07, 10:0.59, 11:0.29\n",
      "[FT] Epoch 5/50  vis_acc=0.5949, par_acc=0.3264\n",
      "    vis per-class: 0:0.49, 1:0.27, 2:0.00, 3:0.71, 4:0.94, 5:0.98, 6:0.95, 7:0.94, 8:1.00, 9:0.60, 10:1.00, 11:0.52\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.51, 4:0.76, 5:0.71, 6:0.33, 7:0.55, 8:0.60, 9:0.04, 10:0.61, 11:0.15\n",
      "[FT] Epoch 6/50  vis_acc=0.5520, par_acc=0.3330\n",
      "    vis per-class: 0:0.36, 1:0.19, 2:0.00, 3:0.81, 4:0.77, 5:0.99, 6:0.95, 7:0.84, 8:0.99, 9:0.64, 10:0.98, 11:0.71\n",
      "    par per-class: 0:0.00, 1:0.00, 2:0.00, 3:0.57, 4:0.62, 5:0.79, 6:0.41, 7:0.40, 8:0.41, 9:0.08, 10:0.71, 11:0.19\n",
      "[FT] Epoch 7/50  vis_acc=0.6111, par_acc=0.3416\n",
      "    vis per-class: 0:0.50, 1:0.36, 2:0.00, 3:0.75, 4:0.89, 5:0.98, 6:0.94, 7:0.93, 8:1.00, 9:0.47, 10:1.00, 11:0.60\n",
      "    par per-class: 0:0.00, 1:0.08, 2:0.00, 3:0.49, 4:0.72, 5:0.66, 6:0.39, 7:0.56, 8:0.47, 9:0.06, 10:0.72, 11:0.20\n",
      "[FT] Epoch 8/50  vis_acc=0.6065, par_acc=0.3437\n",
      "    vis per-class: 0:0.51, 1:0.31, 2:0.00, 3:0.69, 4:0.89, 5:0.96, 6:0.96, 7:0.83, 8:1.00, 9:0.63, 10:1.00, 11:0.63\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.42, 4:0.77, 5:0.64, 6:0.45, 7:0.50, 8:0.50, 9:0.10, 10:0.62, 11:0.24\n",
      "[FT] Epoch 9/50  vis_acc=0.6348, par_acc=0.3382\n",
      "    vis per-class: 0:0.60, 1:0.31, 2:0.00, 3:0.75, 4:0.90, 5:0.97, 6:0.94, 7:0.92, 8:1.00, 9:0.49, 10:1.00, 11:0.50\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.42, 4:0.70, 5:0.76, 6:0.42, 7:0.50, 8:0.58, 9:0.09, 10:0.70, 11:0.17\n",
      "[FT] Epoch 10/50  vis_acc=0.6300, par_acc=0.3419\n",
      "    vis per-class: 0:0.59, 1:0.33, 2:0.00, 3:0.78, 4:0.84, 5:0.98, 6:0.97, 7:0.95, 8:0.99, 9:0.45, 10:1.00, 11:0.49\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.46, 4:0.69, 5:0.73, 6:0.55, 7:0.60, 8:0.41, 9:0.02, 10:0.61, 11:0.19\n",
      "[FT] Epoch 11/50  vis_acc=0.5999, par_acc=0.3384\n",
      "    vis per-class: 0:0.53, 1:0.38, 2:0.00, 3:0.75, 4:0.79, 5:0.98, 6:0.95, 7:0.95, 8:0.99, 9:0.47, 10:1.00, 11:0.44\n",
      "    par per-class: 0:0.00, 1:0.04, 2:0.00, 3:0.47, 4:0.65, 5:0.64, 6:0.55, 7:0.63, 8:0.42, 9:0.03, 10:0.75, 11:0.16\n",
      "[FT] Epoch 12/50  vis_acc=0.5873, par_acc=0.3671\n",
      "    vis per-class: 0:0.42, 1:0.57, 2:0.00, 3:0.88, 4:0.79, 5:0.94, 6:0.85, 7:0.94, 8:0.99, 9:0.46, 10:1.00, 11:0.57\n",
      "    par per-class: 0:0.00, 1:0.26, 2:0.00, 3:0.60, 4:0.73, 5:0.67, 6:0.22, 7:0.65, 8:0.48, 9:0.06, 10:0.77, 11:0.24\n",
      "[FT] Epoch 13/50  vis_acc=0.6542, par_acc=0.2647\n",
      "    vis per-class: 0:0.71, 1:0.25, 2:0.00, 3:0.63, 4:0.93, 5:0.97, 6:0.83, 7:0.95, 8:0.99, 9:0.68, 10:0.96, 11:0.43\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.26, 4:0.72, 5:0.68, 6:0.21, 7:0.56, 8:0.34, 9:0.04, 10:0.52, 11:0.13\n",
      "[FT] Epoch 14/50  vis_acc=0.6201, par_acc=0.3219\n",
      "    vis per-class: 0:0.52, 1:0.34, 2:0.00, 3:0.65, 4:0.89, 5:0.98, 6:0.92, 7:0.96, 8:0.99, 9:0.71, 10:1.00, 11:0.69\n",
      "    par per-class: 0:0.00, 1:0.04, 2:0.00, 3:0.36, 4:0.71, 5:0.67, 6:0.32, 7:0.55, 8:0.37, 9:0.10, 10:0.56, 11:0.25\n",
      "[FT] Epoch 15/50  vis_acc=0.5880, par_acc=0.2928\n",
      "    vis per-class: 0:0.59, 1:0.18, 2:0.00, 3:0.58, 4:0.71, 5:0.98, 6:0.94, 7:0.95, 8:1.00, 9:0.49, 10:1.00, 11:0.49\n",
      "    par per-class: 0:0.00, 1:0.00, 2:0.00, 3:0.35, 4:0.73, 5:0.74, 6:0.36, 7:0.48, 8:0.37, 9:0.01, 10:0.54, 11:0.15\n",
      "[FT] Epoch 16/50  vis_acc=0.6426, par_acc=0.3054\n",
      "    vis per-class: 0:0.62, 1:0.29, 2:0.00, 3:0.74, 4:0.84, 5:0.95, 6:0.88, 7:0.95, 8:1.00, 9:0.72, 10:1.00, 11:0.54\n",
      "    par per-class: 0:0.00, 1:0.04, 2:0.00, 3:0.41, 4:0.74, 5:0.53, 6:0.31, 7:0.66, 8:0.47, 9:0.08, 10:0.54, 11:0.18\n",
      "[FT] Epoch 17/50  vis_acc=0.6968, par_acc=0.3144\n",
      "    vis per-class: 0:0.74, 1:0.28, 2:0.00, 3:0.66, 4:0.89, 5:0.96, 6:0.93, 7:0.98, 8:1.00, 9:0.70, 10:1.00, 11:0.64\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.34, 4:0.73, 5:0.58, 6:0.28, 7:0.67, 8:0.55, 9:0.05, 10:0.62, 11:0.20\n",
      "[FT] Epoch 18/50  vis_acc=0.6981, par_acc=0.3378\n",
      "    vis per-class: 0:0.68, 1:0.40, 2:0.00, 3:0.75, 4:0.88, 5:0.94, 6:0.95, 7:0.97, 8:1.00, 9:0.65, 10:1.00, 11:0.71\n",
      "    par per-class: 0:0.00, 1:0.09, 2:0.00, 3:0.36, 4:0.74, 5:0.59, 6:0.37, 7:0.63, 8:0.44, 9:0.04, 10:0.65, 11:0.25\n",
      "[FT] Epoch 19/50  vis_acc=0.6260, par_acc=0.3389\n",
      "    vis per-class: 0:0.59, 1:0.32, 2:0.00, 3:0.69, 4:0.78, 5:0.95, 6:0.88, 7:0.95, 8:1.00, 9:0.80, 10:1.00, 11:0.58\n",
      "    par per-class: 0:0.00, 1:0.08, 2:0.00, 3:0.33, 4:0.65, 5:0.59, 6:0.27, 7:0.57, 8:0.63, 9:0.17, 10:0.80, 11:0.24\n",
      "[FT] Epoch 20/50  vis_acc=0.7124, par_acc=0.3479\n",
      "    vis per-class: 0:0.68, 1:0.28, 2:0.00, 3:0.87, 4:0.81, 5:0.97, 6:0.92, 7:0.92, 8:1.00, 9:0.84, 10:0.98, 11:0.84\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.52, 4:0.73, 5:0.62, 6:0.35, 7:0.61, 8:0.37, 9:0.16, 10:0.57, 11:0.29\n",
      "[FT] Epoch 21/50  vis_acc=0.7436, par_acc=0.3379\n",
      "    vis per-class: 0:0.77, 1:0.27, 2:0.00, 3:0.86, 4:0.81, 5:0.98, 6:0.90, 7:0.92, 8:1.00, 9:0.83, 10:1.00, 11:0.81\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.49, 4:0.69, 5:0.73, 6:0.28, 7:0.54, 8:0.56, 9:0.16, 10:0.63, 11:0.22\n",
      "[FT] Epoch 22/50  vis_acc=0.6792, par_acc=0.3535\n",
      "    vis per-class: 0:0.60, 1:0.26, 2:0.00, 3:0.82, 4:0.89, 5:0.97, 6:0.98, 7:0.86, 8:1.00, 9:0.86, 10:0.98, 11:0.80\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.43, 4:0.71, 5:0.69, 6:0.53, 7:0.50, 8:0.40, 9:0.22, 10:0.49, 11:0.27\n",
      "[FT] Epoch 23/50  vis_acc=0.7154, par_acc=0.3539\n",
      "    vis per-class: 0:0.68, 1:0.25, 2:0.00, 3:0.82, 4:0.82, 5:0.96, 6:0.97, 7:0.89, 8:0.99, 9:0.91, 10:0.98, 11:0.88\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.48, 4:0.69, 5:0.60, 6:0.49, 7:0.42, 8:0.39, 9:0.29, 10:0.49, 11:0.32\n",
      "[FT] Epoch 24/50  vis_acc=0.7381, par_acc=0.3559\n",
      "    vis per-class: 0:0.76, 1:0.30, 2:0.00, 3:0.82, 4:0.84, 5:0.97, 6:0.95, 7:0.93, 8:1.00, 9:0.79, 10:1.00, 11:0.77\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.44, 4:0.71, 5:0.63, 6:0.41, 7:0.53, 8:0.51, 9:0.13, 10:0.62, 11:0.30\n",
      "[FT] Epoch 25/50  vis_acc=0.7840, par_acc=0.3810\n",
      "    vis per-class: 0:0.81, 1:0.40, 2:0.00, 3:0.84, 4:0.86, 5:0.99, 6:0.96, 7:0.95, 8:1.00, 9:0.80, 10:1.00, 11:0.89\n",
      "    par per-class: 0:0.00, 1:0.05, 2:0.00, 3:0.42, 4:0.71, 5:0.80, 6:0.37, 7:0.59, 8:0.47, 9:0.12, 10:0.53, 11:0.38\n",
      "[FT] Epoch 26/50  vis_acc=0.6460, par_acc=0.3377\n",
      "    vis per-class: 0:0.63, 1:0.34, 2:0.00, 3:0.73, 4:0.88, 5:0.97, 6:0.91, 7:0.92, 8:1.00, 9:0.85, 10:1.00, 11:0.44\n",
      "    par per-class: 0:0.00, 1:0.05, 2:0.00, 3:0.42, 4:0.76, 5:0.62, 6:0.45, 7:0.54, 8:0.59, 9:0.22, 10:0.66, 11:0.15\n",
      "[FT] Epoch 27/50  vis_acc=0.7215, par_acc=0.3265\n",
      "    vis per-class: 0:0.76, 1:0.29, 2:0.00, 3:0.80, 4:0.76, 5:0.94, 6:0.94, 7:0.88, 8:0.98, 9:0.69, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.47, 4:0.70, 5:0.53, 6:0.40, 7:0.49, 8:0.29, 9:0.06, 10:0.48, 11:0.32\n",
      "[FT] Epoch 28/50  vis_acc=0.7171, par_acc=0.3166\n",
      "    vis per-class: 0:0.81, 1:0.30, 2:0.00, 3:0.77, 4:0.64, 5:0.95, 6:0.92, 7:0.91, 8:0.98, 9:0.29, 10:1.00, 11:0.74\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.67, 5:0.60, 6:0.33, 7:0.49, 8:0.40, 9:0.02, 10:0.57, 11:0.28\n",
      "[FT] Epoch 29/50  vis_acc=0.7308, par_acc=0.3156\n",
      "    vis per-class: 0:0.82, 1:0.31, 2:0.00, 3:0.69, 4:0.71, 5:0.95, 6:0.90, 7:0.91, 8:1.00, 9:0.33, 10:1.00, 11:0.85\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.32, 4:0.67, 5:0.61, 6:0.24, 7:0.48, 8:0.56, 9:0.01, 10:0.55, 11:0.31\n",
      "[FT] Epoch 30/50  vis_acc=0.7214, par_acc=0.3196\n",
      "    vis per-class: 0:0.83, 1:0.26, 2:0.00, 3:0.78, 4:0.66, 5:0.90, 6:0.88, 7:0.93, 8:1.00, 9:0.40, 10:1.00, 11:0.75\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.37, 4:0.68, 5:0.48, 6:0.25, 7:0.52, 8:0.64, 9:0.04, 10:0.58, 11:0.30\n",
      "[FT] Epoch 31/50  vis_acc=0.7306, par_acc=0.3408\n",
      "    vis per-class: 0:0.83, 1:0.28, 2:0.00, 3:0.72, 4:0.63, 5:0.96, 6:0.87, 7:0.92, 8:1.00, 9:0.49, 10:1.00, 11:0.85\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.36, 4:0.66, 5:0.60, 6:0.22, 7:0.54, 8:0.57, 9:0.04, 10:0.63, 11:0.37\n",
      "[FT] Epoch 32/50  vis_acc=0.7410, par_acc=0.3372\n",
      "    vis per-class: 0:0.83, 1:0.28, 2:0.00, 3:0.71, 4:0.74, 5:0.97, 6:0.92, 7:0.93, 8:1.00, 9:0.62, 10:1.00, 11:0.78\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.31, 4:0.68, 5:0.65, 6:0.29, 7:0.53, 8:0.49, 9:0.07, 10:0.57, 11:0.34\n",
      "[FT] Epoch 33/50  vis_acc=0.7294, par_acc=0.3199\n",
      "    vis per-class: 0:0.84, 1:0.29, 2:0.00, 3:0.73, 4:0.79, 5:0.96, 6:0.93, 7:0.94, 8:1.00, 9:0.58, 10:1.00, 11:0.60\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.32, 4:0.67, 5:0.67, 6:0.29, 7:0.56, 8:0.56, 9:0.11, 10:0.60, 11:0.23\n",
      "[FT] Epoch 34/50  vis_acc=0.7361, par_acc=0.2941\n",
      "    vis per-class: 0:0.86, 1:0.32, 2:0.00, 3:0.75, 4:0.78, 5:0.96, 6:0.93, 7:0.91, 8:1.00, 9:0.51, 10:1.00, 11:0.56\n",
      "    par per-class: 0:0.00, 1:0.03, 2:0.00, 3:0.38, 4:0.67, 5:0.63, 6:0.29, 7:0.50, 8:0.47, 9:0.06, 10:0.53, 11:0.18\n",
      "[FT] Epoch 35/50  vis_acc=0.7711, par_acc=0.3159\n",
      "    vis per-class: 0:0.89, 1:0.31, 2:0.00, 3:0.78, 4:0.77, 5:0.97, 6:0.93, 7:0.93, 8:1.00, 9:0.45, 10:1.00, 11:0.77\n",
      "    par per-class: 0:0.00, 1:0.02, 2:0.00, 3:0.41, 4:0.61, 5:0.63, 6:0.27, 7:0.54, 8:0.50, 9:0.04, 10:0.51, 11:0.28\n",
      "[FT] Epoch 36/50  vis_acc=0.7480, par_acc=0.3121\n",
      "    vis per-class: 0:0.87, 1:0.21, 2:0.00, 3:0.71, 4:0.74, 5:0.96, 6:0.91, 7:0.89, 8:1.00, 9:0.57, 10:1.00, 11:0.80\n",
      "    par per-class: 0:0.00, 1:0.00, 2:0.00, 3:0.40, 4:0.62, 5:0.62, 6:0.25, 7:0.46, 8:0.52, 9:0.08, 10:0.54, 11:0.28\n",
      "[FT] Epoch 37/50  vis_acc=0.7473, par_acc=0.3175\n",
      "    vis per-class: 0:0.87, 1:0.23, 2:0.00, 3:0.73, 4:0.79, 5:0.96, 6:0.94, 7:0.93, 8:0.99, 9:0.50, 10:1.00, 11:0.70\n",
      "    par per-class: 0:0.00, 1:0.00, 2:0.00, 3:0.39, 4:0.67, 5:0.60, 6:0.31, 7:0.53, 8:0.51, 9:0.07, 10:0.59, 11:0.25\n",
      "[FT] Epoch 38/50  vis_acc=0.7662, par_acc=0.3148\n",
      "    vis per-class: 0:0.90, 1:0.25, 2:0.00, 3:0.73, 4:0.78, 5:0.96, 6:0.95, 7:0.93, 8:0.99, 9:0.51, 10:1.00, 11:0.77\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.38, 4:0.65, 5:0.58, 6:0.32, 7:0.53, 8:0.46, 9:0.06, 10:0.55, 11:0.27\n",
      "[FT] Epoch 39/50  vis_acc=0.7620, par_acc=0.3033\n",
      "    vis per-class: 0:0.90, 1:0.27, 2:0.00, 3:0.71, 4:0.77, 5:0.96, 6:0.94, 7:0.93, 8:1.00, 9:0.47, 10:1.00, 11:0.75\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.37, 4:0.63, 5:0.58, 6:0.29, 7:0.49, 8:0.48, 9:0.06, 10:0.56, 11:0.25\n",
      "[FT] Epoch 40/50  vis_acc=0.7799, par_acc=0.3316\n",
      "    vis per-class: 0:0.89, 1:0.36, 2:0.00, 3:0.74, 4:0.76, 5:0.96, 6:0.94, 7:0.93, 8:1.00, 9:0.52, 10:1.00, 11:0.86\n",
      "    par per-class: 0:0.00, 1:0.04, 2:0.00, 3:0.37, 4:0.63, 5:0.60, 6:0.31, 7:0.50, 8:0.48, 9:0.06, 10:0.54, 11:0.34\n",
      "[FT] Epoch 41/50  vis_acc=0.7748, par_acc=0.3168\n",
      "    vis per-class: 0:0.90, 1:0.30, 2:0.00, 3:0.76, 4:0.77, 5:0.96, 6:0.94, 7:0.91, 8:1.00, 9:0.48, 10:1.00, 11:0.78\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.42, 4:0.64, 5:0.60, 6:0.30, 7:0.49, 8:0.51, 9:0.05, 10:0.56, 11:0.27\n",
      "[FT] Epoch 42/50  vis_acc=0.7705, par_acc=0.3153\n",
      "    vis per-class: 0:0.90, 1:0.27, 2:0.00, 3:0.74, 4:0.75, 5:0.96, 6:0.94, 7:0.91, 8:1.00, 9:0.53, 10:1.00, 11:0.80\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.40, 4:0.65, 5:0.58, 6:0.29, 7:0.46, 8:0.50, 9:0.06, 10:0.55, 11:0.28\n",
      "[FT] Epoch 43/50  vis_acc=0.7769, par_acc=0.3087\n",
      "    vis per-class: 0:0.92, 1:0.26, 2:0.00, 3:0.76, 4:0.74, 5:0.97, 6:0.94, 7:0.92, 8:1.00, 9:0.48, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.63, 5:0.61, 6:0.31, 7:0.48, 8:0.46, 9:0.04, 10:0.51, 11:0.26\n",
      "[FT] Epoch 44/50  vis_acc=0.7798, par_acc=0.3161\n",
      "    vis per-class: 0:0.92, 1:0.25, 2:0.00, 3:0.76, 4:0.74, 5:0.97, 6:0.95, 7:0.92, 8:1.00, 9:0.55, 10:1.00, 11:0.81\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.62, 5:0.59, 6:0.32, 7:0.48, 8:0.45, 9:0.06, 10:0.53, 11:0.29\n",
      "[FT] Epoch 45/50  vis_acc=0.7777, par_acc=0.3124\n",
      "    vis per-class: 0:0.92, 1:0.26, 2:0.00, 3:0.76, 4:0.76, 5:0.97, 6:0.95, 7:0.92, 8:1.00, 9:0.49, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.63, 5:0.59, 6:0.32, 7:0.48, 8:0.49, 9:0.05, 10:0.53, 11:0.27\n",
      "[FT] Epoch 46/50  vis_acc=0.7774, par_acc=0.3091\n",
      "    vis per-class: 0:0.92, 1:0.25, 2:0.00, 3:0.76, 4:0.75, 5:0.96, 6:0.95, 7:0.92, 8:1.00, 9:0.50, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.62, 5:0.59, 6:0.32, 7:0.47, 8:0.49, 9:0.05, 10:0.51, 11:0.26\n",
      "[FT] Epoch 47/50  vis_acc=0.7788, par_acc=0.3087\n",
      "    vis per-class: 0:0.92, 1:0.25, 2:0.00, 3:0.77, 4:0.74, 5:0.96, 6:0.95, 7:0.92, 8:1.00, 9:0.52, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.42, 4:0.61, 5:0.59, 6:0.32, 7:0.48, 8:0.48, 9:0.06, 10:0.51, 11:0.26\n",
      "[FT] Epoch 48/50  vis_acc=0.7803, par_acc=0.3084\n",
      "    vis per-class: 0:0.92, 1:0.25, 2:0.00, 3:0.76, 4:0.75, 5:0.96, 6:0.95, 7:0.92, 8:1.00, 9:0.54, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.42, 4:0.61, 5:0.59, 6:0.32, 7:0.48, 8:0.48, 9:0.06, 10:0.51, 11:0.26\n",
      "[FT] Epoch 49/50  vis_acc=0.7808, par_acc=0.3070\n",
      "    vis per-class: 0:0.93, 1:0.25, 2:0.00, 3:0.76, 4:0.75, 5:0.96, 6:0.95, 7:0.92, 8:1.00, 9:0.53, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.41, 4:0.61, 5:0.58, 6:0.32, 7:0.47, 8:0.48, 9:0.06, 10:0.51, 11:0.26\n",
      "[FT] Epoch 50/50  vis_acc=0.7808, par_acc=0.3074\n",
      "    vis per-class: 0:0.93, 1:0.25, 2:0.00, 3:0.77, 4:0.75, 5:0.96, 6:0.95, 7:0.92, 8:1.00, 9:0.54, 10:1.00, 11:0.79\n",
      "    par per-class: 0:0.00, 1:0.01, 2:0.00, 3:0.42, 4:0.61, 5:0.59, 6:0.32, 7:0.48, 8:0.48, 9:0.06, 10:0.51, 11:0.26\n",
      "[FT] Best score (vis) after finetune: 0.783965 (epoch 25)\n",
      "Saved ft_partial_best to: /kaggle/working/cls_ckpt_ft_partial/ft_partial_best.pt\n"
     ]
    }
   ],
   "source": [
    "import os, argparse, itertools\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import torch, timm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torch import amp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "# dùng lại LetterboxSquare, PreprocessUpsample như file gốc\n",
    "\n",
    "def remap_to_vis_mapping(ds, vis_class_to_idx, vis_classes):\n",
    "    \"\"\"\n",
    "    Remap ImageFolder dataset `ds` sang mapping của visible theo tên folder.\n",
    "    - ds: ImageFolder (partial)\n",
    "    - vis_class_to_idx: mapping của visible (vd {'00':0, '01':1, ...})\n",
    "    - vis_classes: list tên class của visible\n",
    "    \"\"\"\n",
    "    new_samples = []\n",
    "    for path, _ in ds.samples:\n",
    "        cls_name = Path(path).parent.name  # tên folder, ví dụ '02'\n",
    "        if cls_name not in vis_class_to_idx:\n",
    "            # partial có class mà visible không có -> lỗi thật\n",
    "            raise ValueError(f\"Class '{cls_name}' trong partial KHÔNG tồn tại trong visible. Sửa lại folder trước.\")\n",
    "        new_label = vis_class_to_idx[cls_name]\n",
    "        new_samples.append((path, new_label))\n",
    "\n",
    "    ds.samples = new_samples\n",
    "    ds.targets = [s[1] for s in new_samples]\n",
    "    ds.class_to_idx = vis_class_to_idx\n",
    "    ds.classes = vis_classes\n",
    "    return ds\n",
    "\n",
    "def finetune_with_partial(\n",
    "    root=\"/kaggle/input/datav2/dataset_clsv2\",\n",
    "    ckpt_path=\"/kaggle/working/cls_ckpt/best.pt\",\n",
    "    outdir=\"/kaggle/working/cls_ckpt_ft_partial\",\n",
    "    model_name=\"convnext_tiny\",\n",
    "    weak_classes=(2,),          # class yếu (02 + có thể thêm 1,9,...)\n",
    "    boost_factor=4.0,\n",
    "    epochs=20,\n",
    "    bs=140,\n",
    "    size=224,\n",
    "    lr=5e-5,\n",
    "    alpha0=0.15,\n",
    "    use_sampler=True,\n",
    "    workers=4,\n",
    "):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) loaders dùng cả visible + partial\n",
    "    (train_loader,\n",
    "     val_loader_visible,\n",
    "     val_loader_partial,\n",
    "     classes,\n",
    "     weights_ce,\n",
    "     counts) = get_loaders_with_partial(\n",
    "        root=root,\n",
    "        bs=bs,\n",
    "        size=size,\n",
    "        workers=workers,\n",
    "        use_sampler=use_sampler,\n",
    "        alpha0=alpha0\n",
    "    )\n",
    "\n",
    "    n_classes = len(classes)\n",
    "    print(\"Classes:\", classes)\n",
    "    print(\"Train class counts (vis+partial):\", {i:int(c.item()) for i,c in enumerate(counts)})\n",
    "    print(\"Weak classes:\", weak_classes)\n",
    "\n",
    "    # 2) buff weight cho class yếu\n",
    "    weights_ft = weights_ce.clone()\n",
    "    for c in weak_classes:\n",
    "        if 0 <= c < n_classes:\n",
    "            print(f\"Boosting loss weight for class {c} by x{boost_factor}\")\n",
    "            weights_ft[c] *= float(boost_factor)\n",
    "    weights_ft = weights_ft / weights_ft.sum() * len(weights_ft)\n",
    "\n",
    "    # 3) load model từ ckpt visible\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=n_classes)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_ft.to(device))\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
    "    scaler = amp.GradScaler(\"cuda\", enabled=torch.cuda.is_available())\n",
    "\n",
    "    best_vis = 0.0\n",
    "    best_ep = -1\n",
    "\n",
    "    print(\"=== Start finetune on visible + partial ===\")\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            with amp.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "\n",
    "        # đánh giá trên visible + partial để xem trade-off\n",
    "\n",
    "        acc_vis, cm_vis, pc_vis = evaluate(model, val_loader_visible, device, n_classes)\n",
    "        acc_par, cm_par, pc_par = evaluate(model, val_loader_partial, device, n_classes)\n",
    "\n",
    "        sched.step()\n",
    "\n",
    "        print(f\"[FT] Epoch {ep}/{epochs}  vis_acc={acc_vis:.4f}, par_acc={acc_par:.4f}\")\n",
    "        print(\"    vis per-class:\", \", \".join(f\"{i}:{a:.2f}\" for i,a in enumerate(pc_vis)))\n",
    "        print(\"    par per-class:\", \", \".join(f\"{i}:{a:.2f}\" for i,a in enumerate(pc_par)))\n",
    "\n",
    "        torch.save({\"model\": model.state_dict(), \"classes\": classes},\n",
    "                   outdir / \"ft_partial_last.pt\")\n",
    "\n",
    "        # chọn best theo visible hoặc trung bình (tuỳ anh)\n",
    "        score = acc_vis  # hoặc (acc_vis + acc_par) / 2\n",
    "        if score > best_vis:\n",
    "            best_vis = score\n",
    "            best_ep = ep\n",
    "            torch.save({\"model\": model.state_dict(), \"classes\": classes},\n",
    "                       outdir / \"ft_partial_best.pt\")\n",
    "\n",
    "    print(f\"[FT] Best score (vis) after finetune: {best_vis:.6f} (epoch {best_ep})\")\n",
    "    print(f\"Saved ft_partial_best to: {outdir/'ft_partial_best.pt'}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dùng lại đúng 2 class bạn đã có:\n",
    "class LetterboxSquare(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img: Image.Image):\n",
    "        w, h = img.size\n",
    "        s = min(self.size / w, self.size / h)\n",
    "        nw, nh = int(round(w * s)), int(round(h * s))\n",
    "\n",
    "        img = img.resize((nw, nh), Image.BILINEAR)\n",
    "\n",
    "        pad_l = (self.size - nw) // 2\n",
    "        pad_t = (self.size - nh) // 2\n",
    "        pad_r = self.size - nw - pad_l\n",
    "        pad_b = self.size - nh - pad_t\n",
    "\n",
    "        return transforms.functional.pad(\n",
    "            img,\n",
    "            (pad_l, pad_t, pad_r, pad_b),\n",
    "            padding_mode=\"reflect\"\n",
    "        )\n",
    "\n",
    "class PreprocessUpsample(object):\n",
    "    def __init__(self, out_size, unsharp_radius=1, unsharp_percent=150, unsharp_threshold=3):\n",
    "        self.out_size = out_size\n",
    "        self.radius = unsharp_radius\n",
    "        self.percent = unsharp_percent\n",
    "        self.threshold = unsharp_threshold\n",
    "\n",
    "    def __call__(self, img: Image.Image):\n",
    "        img = img.resize((self.out_size, self.out_size), resample=Image.BICUBIC)\n",
    "        img = img.filter(ImageFilter.UnsharpMask(radius=self.radius,\n",
    "                                                 percent=self.percent,\n",
    "                                                 threshold=self.threshold))\n",
    "        return img\n",
    "\n",
    "\n",
    "def get_loaders_with_partial(root=\"/kaggle/input/datav2/dataset_clsv2\",\n",
    "                             bs=140, size=224, workers=4,\n",
    "                             use_sampler=True, alpha0=0.15,\n",
    "                             partial_factor=0.3):\n",
    "    MEAN, STD = (0.485,0.456,0.406), (0.229,0.224,0.225)\n",
    "\n",
    "    prep = PreprocessUpsample(size)\n",
    "\n",
    "    tf_train = transforms.Compose([\n",
    "        LetterboxSquare(size),\n",
    "        prep,\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "\n",
    "    tf_val = transforms.Compose([\n",
    "        LetterboxSquare(size),\n",
    "        prep,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "\n",
    "    root = Path(root)\n",
    "\n",
    "    # === visible ===\n",
    "    vis_train = datasets.ImageFolder(root/\"visible\"/\"train\", tf_train)\n",
    "    vis_val   = datasets.ImageFolder(root/\"visible\"/\"val\",   tf_val)\n",
    "\n",
    "    vis_classes = vis_train.classes\n",
    "    vis_class_to_idx = vis_train.class_to_idx\n",
    "    n_classes = len(vis_classes)\n",
    "\n",
    "    # === partial (raw) ===\n",
    "    part_train_raw = datasets.ImageFolder(root/\"partial\"/\"train\", tf_train)\n",
    "    part_val_raw   = datasets.ImageFolder(root/\"partial\"/\"val\",   tf_val)\n",
    "\n",
    "    print(\"VISIBLE classes:\", vis_classes)\n",
    "    print(\"PARTIAL raw classes:\", part_train_raw.classes)\n",
    "\n",
    "    # remap partial -> dùng chung mapping với visible\n",
    "    part_train = remap_to_vis_mapping(part_train_raw, vis_class_to_idx, vis_classes)\n",
    "    part_val   = remap_to_vis_mapping(part_val_raw,   vis_class_to_idx, vis_classes)\n",
    "\n",
    "    # ===== train dataset gộp: visible + partial =====\n",
    "    train_ds = ConcatDataset([vis_train, part_train])\n",
    "\n",
    "    # ===== val loader =====\n",
    "    val_ds_visible = vis_val\n",
    "    val_ds_partial = part_val\n",
    "\n",
    "    # ----- class counts & weights (trên train gộp) -----\n",
    "    counts = torch.zeros(n_classes, dtype=torch.float32)\n",
    "    for ds_ in [vis_train, part_train]:\n",
    "        for _, y in ds_.samples:\n",
    "            counts[y] += 1\n",
    "\n",
    "    inv = 1.0 / (counts + 1e-6)\n",
    "    weights_ce = inv / inv.sum() * len(inv)\n",
    "\n",
    "    # deweight class 0\n",
    "    weights_ce[0] *= float(alpha0)\n",
    "    weights_ce = weights_ce / weights_ce.sum() * len(weights_ce)\n",
    "\n",
    "    # ----- sampler -----\n",
    "       # ----- sampler -----\n",
    "    if use_sampler:\n",
    "        per_class_sample_w = inv.clone()\n",
    "        per_class_sample_w[0] *= float(alpha0)\n",
    "        per_class_sample_w = per_class_sample_w / per_class_sample_w.sum() * len(per_class_sample_w)\n",
    "\n",
    "        sample_weights = []\n",
    "        # visible bình thường, partial bị giảm weight theo partial_factor\n",
    "        for ds_ in [vis_train, part_train]:\n",
    "            is_partial = (ds_ is part_train)\n",
    "            for _, y in ds_.samples:\n",
    "                w = per_class_sample_w[y].item()\n",
    "                if is_partial:\n",
    "                    w *= partial_factor   # <== chỗ này làm partial \"yếu\" hơn\n",
    "                sample_weights.append(w)\n",
    "\n",
    "        sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "\n",
    "        sampler = WeightedRandomSampler(\n",
    "            sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, batch_size=bs, sampler=sampler,\n",
    "            num_workers=workers, pin_memory=True\n",
    "        )\n",
    "    else:\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, batch_size=bs, shuffle=True,\n",
    "            num_workers=workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "    val_loader_visible = DataLoader(\n",
    "        val_ds_visible, batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True\n",
    "    )\n",
    "    val_loader_partial = DataLoader(\n",
    "        val_ds_partial, batch_size=bs, shuffle=False,\n",
    "        num_workers=workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return (train_loader,\n",
    "            val_loader_visible,\n",
    "            val_loader_partial,\n",
    "            vis_classes,\n",
    "            weights_ce,\n",
    "            counts)\n",
    "\n",
    "\n",
    "def get_loaders(root=\"/kaggle/input/datav2/dataset_clsv2/visible\", bs=120, size=224, workers=4, use_sampler=False, alpha0=0.05):\n",
    "    MEAN, STD = (0.485,0.456,0.406), (0.229,0.224,0.225)\n",
    "\n",
    "    prep = PreprocessUpsample(size)   # thực hiện upsample + unsharp\n",
    "\n",
    "    tf_train = transforms.Compose([\n",
    "        LetterboxSquare(size),          # giữ nội dung, letterbox\n",
    "        prep,                           # bicubic resize -> unsharp\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "        # transforms.GaussianBlur(kernel_size=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "\n",
    "    tf_val = transforms.Compose([\n",
    "        LetterboxSquare(size),\n",
    "        prep,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ])\n",
    "    train_ds = datasets.ImageFolder(f\"{root}/train\", tf_train)\n",
    "    val_ds   = datasets.ImageFolder(f\"{root}/val\",   tf_val)\n",
    "\n",
    "    # ----- class counts & weights -----\n",
    "    counts = torch.zeros(len(train_ds.classes), dtype=torch.float32)\n",
    "    for _, y in train_ds.samples:\n",
    "        counts[y] += 1\n",
    "    inv = 1.0 / (counts + 1e-6)\n",
    "    weights_ce = inv / inv.sum() * len(inv)\n",
    "\n",
    "    # deweight class 0 in loss\n",
    "    weights_ce[0] *= float(alpha0)\n",
    "    weights_ce = weights_ce / weights_ce.sum() * len(weights_ce)\n",
    "\n",
    "    # ----- sampler (optional) -----\n",
    "    if use_sampler:\n",
    "        # sample weight per-sample ~ 1/freq, nhưng cũng giảm class 0 trong sampler\n",
    "        per_class_sample_w = inv.clone()\n",
    "        per_class_sample_w[0] *= float(alpha0)\n",
    "        per_class_sample_w = per_class_sample_w / per_class_sample_w.sum() * len(per_class_sample_w)\n",
    "        sample_weights = torch.tensor([per_class_sample_w[y] for _, y in train_ds.samples], dtype=torch.float32)\n",
    "        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        train_loader = DataLoader(train_ds, batch_size=bs, sampler=sampler, num_workers=workers, pin_memory=True)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=bs, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "    return train_loader, val_loader, train_ds.classes, weights_ce, counts\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, n_classes):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    tot = 0\n",
    "    # confusion matrix\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        tot += y.numel()\n",
    "        for t, p in zip(y.view(-1), pred.view(-1)):\n",
    "            cm[int(t.item()), int(p.item())] += 1\n",
    "    acc = correct / tot if tot else 0.0\n",
    "    # per-class acc\n",
    "    per_class_acc = []\n",
    "    for c in range(n_classes):\n",
    "        denom = cm[c].sum()\n",
    "        per_class_acc.append(cm[c, c] / denom if denom > 0 else 0.0)\n",
    "    return acc, cm, per_class_acc\n",
    "\n",
    "def pretty_cm(cm, classes):\n",
    "    # compact text table (first 6 cols if too wide)\n",
    "    head = \"     \" + \" \".join([f\"{i:>4}\" for i in range(len(classes))])\n",
    "    rows = []\n",
    "    for i in range(len(classes)):\n",
    "        rows.append(f\"{i:>3}: \" + \" \".join([f\"{cm[i,j]:>4}\" for j in range(len(classes))]))\n",
    "    return head + \"\\n\" + \"\\n\".join(rows)\n",
    "\n",
    "def finetune_weak_classes(\n",
    "    root=\"/kaggle/input/datav2/dataset_clsv2/visible\",\n",
    "    ckpt_path=\"/kaggle/working/cls_ckpt/best.pt\",\n",
    "    outdir=\"/kaggle/working/cls_ckpt_ft\",\n",
    "    model_name=\"convnext_tiny\",\n",
    "    weak_classes=(2,),          # class yếu, mặc định buff riêng 02\n",
    "    boost_factor=4.0,           # nhân weight trong loss cho các class yếu\n",
    "    epochs=20,\n",
    "    bs=120,\n",
    "    size=224,\n",
    "    lr=5e-5,\n",
    "    alpha0=0.05,\n",
    "    use_sampler=True,\n",
    "    workers=4,\n",
    "    pretrained=False            # finetune từ ckpt nên không cần pretrained\n",
    "):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Tạo lại loaders + weights_ce như ban đầu\n",
    "    train_loader, val_loader, classes, weights_ce, counts = get_loaders(\n",
    "        root=root,\n",
    "        bs=bs,\n",
    "        size=size,\n",
    "        workers=workers,\n",
    "        use_sampler=use_sampler,\n",
    "        alpha0=alpha0\n",
    "    )\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    print(\"Classes:\", classes)\n",
    "    print(\"Train class counts:\", {i:int(c.item()) for i,c in enumerate(counts)})\n",
    "    print(\"Weak classes:\", weak_classes)\n",
    "\n",
    "    # 2) Tăng weight cho class yếu trong loss\n",
    "    weights_ft = weights_ce.clone()\n",
    "    for c in weak_classes:\n",
    "        if 0 <= c < n_classes:\n",
    "            print(f\"Boosting loss weight for class {c} by x{boost_factor}\")\n",
    "            weights_ft[c] *= float(boost_factor)\n",
    "        else:\n",
    "            print(f\"[WARN] class index {c} ngoài range, bỏ qua.\")\n",
    "\n",
    "    # chuẩn hóa lại cho đẹp (không bắt buộc nhưng gọn)\n",
    "    weights_ft = weights_ft / weights_ft.sum() * len(weights_ft)\n",
    "\n",
    "    print(\"Original CE weights :\", weights_ce.cpu().numpy())\n",
    "    print(\"Finetune CE weights :\", weights_ft.cpu().numpy())\n",
    "\n",
    "    # 3) Tạo model + load ckpt tốt nhất\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=n_classes)\n",
    "    backbone.load_state_dict(ckpt[\"model\"])\n",
    "    backbone.to(device)\n",
    "\n",
    "    # 4) Loss, optimizer, scheduler\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_ft.to(device))\n",
    "    optim = torch.optim.AdamW(backbone.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
    "    scaler = amp.GradScaler(\"cuda\", enabled=torch.cuda.is_available())\n",
    "\n",
    "    best = 0.0\n",
    "    best_ep = -1\n",
    "\n",
    "    print(\"=== Start finetune on weak classes ===\")\n",
    "    for ep in range(1, epochs + 1):\n",
    "        backbone.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            with amp.autocast(\"cuda\", enabled=torch.cuda.is_available()):\n",
    "                logits = backbone(x)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "\n",
    "        acc, cm, per_class = evaluate(backbone, val_loader, device, n_classes)\n",
    "        sched.step()\n",
    "\n",
    "        print(f\"[FT] Epoch {ep}/{epochs}  val_acc={acc:.4f}  | per-class acc: \"\n",
    "              + ', '.join(f'{i}:{a:.2f}' for i, a in enumerate(per_class)))\n",
    "        # Nếu muốn xem confusion matrix:\n",
    "        # print(pretty_cm(cm, classes))\n",
    "\n",
    "        # save last\n",
    "        torch.save({\"model\": backbone.state_dict(), \"classes\": classes},\n",
    "                   outdir / \"ft_last.pt\")\n",
    "\n",
    "        # save best theo val_acc (sau finetune)\n",
    "        if acc > best:\n",
    "            best = acc\n",
    "            best_ep = ep\n",
    "            torch.save({\"model\": backbone.state_dict(), \"classes\": classes},\n",
    "                       outdir / \"ft_best.pt\")\n",
    "\n",
    "    print(f\"[FT] Best val acc after finetune: {best:.6f} (epoch {best_ep})\")\n",
    "    print(f\"Saved ft_best to: {outdir/'ft_best.pt'} | ft_last to: {outdir/'ft_last.pt'}\")\n",
    "\n",
    "    return backbone\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ví dụ chạy finetune chỉ buff class 02\n",
    "    # finetune_weak_classes(\n",
    "    #     root=\"/kaggle/input/datav2/dataset_clsv2/visible\",\n",
    "    #     ckpt_path=\"/kaggle/input/bestpt2/best2.pt\",\n",
    "    #     outdir=\"/kaggle/working/cls_ckpt_ft\",\n",
    "    #     model_name=\"convnext_tiny\",\n",
    "    #     weak_classes=(2,1),      # nếu muốn buff thêm class 1,9: (2,1,9)\n",
    "    #     boost_factor=4.0,\n",
    "    #     epochs=20,\n",
    "    #     bs=120,\n",
    "    #     size=224,\n",
    "    #     lr=5e-5,\n",
    "    #     alpha0=0.05,\n",
    "    #     use_sampler=True,\n",
    "    #     workers=4\n",
    "    # )\n",
    "# trong notebook\n",
    "    finetune_with_partial(\n",
    "        root=\"/kaggle/input/datav2/dataset_clsv2\",\n",
    "        ckpt_path=\"/kaggle/input/bestpt3/ft_best.pt\",  # model đã train trên visible\n",
    "        weak_classes=(2,1),      # thêm class yếu khác nếu cần\n",
    "        boost_factor=3.0,\n",
    "        epochs=50,\n",
    "        lr=1e-4\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8769082,
     "sourceId": 13777177,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8782078,
     "sourceId": 13794092,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30125.357559,
   "end_time": "2025-11-25T01:55:58.358688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-24T17:33:53.001129",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
